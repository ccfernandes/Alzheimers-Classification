{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import scipy as sp\n",
    "import time\n",
    "import operator\n",
    "from random import randrange\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class distanceMetrics:\n",
    "    '''\n",
    "    Description:\n",
    "        This class contains methods to calculate various distance metrics\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Description:\n",
    "            Initialization/Constructor function\n",
    "        '''\n",
    "        pass\n",
    "        \n",
    "    def euclideanDistance(self, vector1, vector2):\n",
    "        '''\n",
    "        Description:\n",
    "            Function to calculate Euclidean Distance\n",
    "                \n",
    "        Inputs:\n",
    "            vector1, vector2: input vectors for which the distance is to be calculated\n",
    "        Output:\n",
    "            Calculated euclidean distance of two vectors\n",
    "        '''\n",
    "        self.vectorA, self.vectorB = vector1, vector2\n",
    "        if len(self.vectorA) != len(self.vectorB):\n",
    "            raise ValueError(\"Undefined for sequences of unequal length.\")\n",
    "        distance = 0.0\n",
    "        for i in range(len(self.vectorA)-1):\n",
    "            distance += (self.vectorA[i] - self.vectorB[i])**2\n",
    "        return (distance)**0.5\n",
    "    \n",
    "    def manhattanDistance(self, vector1, vector2):\n",
    "        \"\"\"\n",
    "        Desription:\n",
    "            Takes 2 vectors a, b and returns the manhattan distance\n",
    "        Inputs:\n",
    "            vector1, vector2: two vectors for which the distance is to be calculated\n",
    "        Output:\n",
    "            Manhattan Distance of two input vectors\n",
    "        \"\"\"\n",
    "        self.vectorA, self.vectorB = vector1, vector2\n",
    "        if len(self.vectorA) != len(self.vectorB):\n",
    "            raise ValueError(\"Undefined for sequences of unequal length.\")\n",
    "        return np.abs(np.array(self.vectorA) - np.array(self.vectorB)).sum()\n",
    "    \n",
    "    def hammingDistance(self, vector1, vector2):\n",
    "        \"\"\"\n",
    "        Desription:\n",
    "            Takes 2 vectors a, b and returns the hamming distance\n",
    "            Hamming distance is meant for discrete-valued vectors, though it is a \n",
    "            valid metric for real-valued vectors.\n",
    "        Inputs:\n",
    "            vector1, vector2: two vectors for which the distance is to be calculated\n",
    "        Output:\n",
    "           Hamming Distance of two input vectors \n",
    "        \"\"\"\n",
    "        self.vectorA, self.vectorB = vector1, vector2\n",
    "        if len(self.vectorA) != len(self.vectorB):\n",
    "            raise ValueError(\"Undefined for sequences of unequal length.\")\n",
    "        return sum(el1 != el2 for el1, el2 in zip(self.vectorA, self.vectorB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNNClassifier:\n",
    "    '''\n",
    "    Description:\n",
    "        This class contains the functions to calculate distances\n",
    "    '''\n",
    "    def __init__(self,k = 3, distanceMetric = 'euclidean'):\n",
    "        '''\n",
    "        Description:\n",
    "            KNearestNeighbors constructor\n",
    "        Input    \n",
    "            k: total of neighbors. Defaulted to 3\n",
    "            distanceMetric: type of distance metric to be used. Defaulted to euclidean distance.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def fit(self, xTrain, yTrain):\n",
    "        '''\n",
    "        Description:\n",
    "            Train kNN model with x data\n",
    "        Input:\n",
    "            xTrain: training data with coordinates\n",
    "            yTrain: labels of training data set\n",
    "        Output:\n",
    "            None\n",
    "        '''\n",
    "        assert len(xTrain) == len(yTrain)\n",
    "        self.trainData = xTrain\n",
    "        self.trainLabels = yTrain\n",
    "\n",
    "    def getNeighbors(self, testRow):\n",
    "        '''\n",
    "        Description:\n",
    "            Train kNN model with x data\n",
    "        Input:\n",
    "            testRow: testing data with coordinates\n",
    "        Output:\n",
    "            k-nearest neighbors to the test data\n",
    "        '''\n",
    "        \n",
    "        calcDM = distanceMetrics()\n",
    "        distances = []\n",
    "        for i, trainRow in enumerate(self.trainData):\n",
    "            if self.distanceMetric == 'euclidean':\n",
    "                distances.append([trainRow, calcDM.euclideanDistance(testRow, trainRow), self.trainLabels[i]])\n",
    "            elif self.distanceMetric == 'manhattan':\n",
    "                distances.append([trainRow, calcDM.manhattanDistance(testRow, trainRow), self.trainLabels[i]])\n",
    "            elif self.distanceMetric == 'hamming':\n",
    "                distances.append([trainRow, calcDM.hammingDistance(testRow, trainRow), self.trainLabels[i]])\n",
    "            distances.sort(key=operator.itemgetter(1))\n",
    "\n",
    "        neighbors = []\n",
    "        for index in range(self.k):\n",
    "            neighbors.append(distances[index])\n",
    "        return neighbors\n",
    "    \n",
    "    def predict(self, xTest, k, distanceMetric):\n",
    "        '''\n",
    "        Description:\n",
    "            Apply kNN model on test data\n",
    "        Input:\n",
    "            xTest: testing data with coordinates\n",
    "            k: number of neighbors\n",
    "            distanceMetric: technique to calculate distance metric\n",
    "        Output:\n",
    "            predicted label \n",
    "        '''\n",
    "        self.testData = xTest\n",
    "        self.k = k\n",
    "        self.distanceMetric = distanceMetric\n",
    "        predictions = []\n",
    "        \n",
    "        for i, testCase in enumerate(self.testData):\n",
    "            neighbors = self.getNeighbors(testCase)\n",
    "            output= [row[-1] for row in neighbors]\n",
    "            prediction = max(set(output), key=output.count)\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(actual, predictions):\n",
    "    '''\n",
    "    Description:\n",
    "        This method calculates the accuracy of predictions\n",
    "    '''\n",
    "    assert len(actual) == len(predictions)\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(actual)) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kFoldCV:\n",
    "    '''\n",
    "    Class to perform k-Fold Cross Validation on a dataet\n",
    "    '''\n",
    "    \n",
    "    def __init_(self):\n",
    "        pass\n",
    "    \n",
    "    #function to split the datasets into training and test. The output for this function is the split dataset\n",
    "    def crossValSplit(self,dataset,numfolds):\n",
    "        datasplit = list()\n",
    "        datacopy = list(dataset)\n",
    "        foldsize = int(len(dataset)/numfolds)\n",
    "        for _ in range(numfolds):\n",
    "            fold = list()\n",
    "            while len(fold) < foldsize:\n",
    "                index = randrange(len(datacopy))\n",
    "                fold.append(datacopy.pop(index))\n",
    "            datasplit.append(fold)\n",
    "        return datasplit\n",
    "    \n",
    "    def KFCVEvaluate(self,dataset,numfolds,*args):\n",
    "        '''\n",
    "        This is the driver function for the k-Fold Cross Validation\n",
    "        '''\n",
    "        knn = kNNClassifier()\n",
    "        folds = self.crossValSplit(dataset, numfolds)\n",
    "        scores = list()\n",
    "        for fold in folds:\n",
    "            trainSet = list(folds)\n",
    "            trainSet.remove(fold)\n",
    "            trainSet = sum(trainSet,[])\n",
    "            testSet =list()\n",
    "            for row in fold:\n",
    "                rowCopy = list(row)\n",
    "                testSet.append(rowCopy)\n",
    "                \n",
    "            trainLabels = [row[-1] for row in trainSet]\n",
    "            trainSet = [train[:-1] for train in trainSet]\n",
    "            knn.fit(trainSet,trainLabels)\n",
    "            \n",
    "            actual = [row[-1] for rwo in testSet]\n",
    "            testSet = [test[:-1] for test in testSet]\n",
    "            \n",
    "            predicted = knn.predict(testSet, *args)\n",
    "            \n",
    "            accuracy = printMetrics(actual,predicted)\n",
    "            scores.append(accuracy)\n",
    "            \n",
    "        print('*'*20)\n",
    "        print('Scores: %s' % scores)\n",
    "        print('*'*20)\n",
    "        print('\\nMaximum Accuracy: %3f%%' % max(scores))\n",
    "        print('\\nMean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\AZD\\\\Desktop\\\\ANOVA_test_new.csv\")\n",
    "data1 = pd.DataFrame(data)\n",
    "data1 = data1.apply(preprocessing.LabelEncoder().fit_transform)\n",
    "features = data1.values.tolist()\n",
    "labels = [MCI[-1] for MCI in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Scores: [74.50980392156863, 3.431372549019608, 21.568627450980394, 0.0, 75.98039215686273, 16.666666666666664]\n",
      "********************\n",
      "\n",
      "Maximum Accuracy: 75.980392%\n",
      "\n",
      "Mean Accuracy: 32.026%\n"
     ]
    }
   ],
   "source": [
    "kfcv = kFoldCV()\n",
    "kfcv.KFCVEvaluate(features, 6, 40,'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Scores: [18.137254901960784, 77.45098039215686, 70.09803921568627, 24.509803921568626, 75.49019607843137, 20.098039215686274]\n",
      "********************\n",
      "\n",
      "Maximum Accuracy: 77.450980%\n",
      "\n",
      "Mean Accuracy: 47.631%\n"
     ]
    }
   ],
   "source": [
    "kfcv.KFCVEvaluate(features, 6, 40, 'hamming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kfcv.KFCVEvaluate(features, 5, 40, 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
