{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "dataset = pd.read_csv(\"C:\\\\Users\\\\AZD\\\\Desktop\\\\merged_normalized_4_COPY1_COPY2.csv\", header=0) # merged_normalized_4_COPY1\n",
    "# dataset = pd.read_csv(\"C:\\\\Users\\\\AZD\\\\Desktop\\\\boxplot_validation_set.csv\", header=0)\n",
    "dataset=dataset.dropna()\n",
    "\n",
    "# merged normalized_4\n",
    "X = dataset.iloc[:, 0:22]\n",
    "y = dataset.iloc[:, 23]\n",
    "\n",
    "#box-plot validation\n",
    "# X = dataset.iloc[:, 0:7].values \n",
    "# y = dataset.iloc[:, 8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0) \n",
    "  \n",
    "# training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 4).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, dtree_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 28  14]\n",
      " [  9 104]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.67      0.71        42\n",
      "           1       0.88      0.92      0.90       113\n",
      "\n",
      "    accuracy                           0.85       155\n",
      "   macro avg       0.82      0.79      0.80       155\n",
      "weighted avg       0.85      0.85      0.85       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8516129032258064\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test, y_test) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22  20]\n",
      " [  7 106]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.62        42\n",
      "           1       0.84      0.94      0.89       113\n",
      "\n",
      "    accuracy                           0.83       155\n",
      "   macro avg       0.80      0.73      0.75       155\n",
      "weighted avg       0.82      0.83      0.81       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8258064516129032\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7354838709677419\n"
     ]
    }
   ],
   "source": [
    "# training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test, y_test) \n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test)  \n",
    "cm = confusion_matrix(y_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7  35]\n",
      " [  6 107]]\n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1\n",
      " 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1]\n",
      "      AGE  APOE4  PTGENDER  PTMARRY  PTEDUCAT  PTRACCAT  MEM_AVG  LANG_AVG  \\\n",
      "886  83.4    1.0      -1.0      1.0      18.0       5.0  0.25000  0.333333   \n",
      "869  70.8    1.0      -1.0      1.0      20.0       5.0  0.56250  0.527778   \n",
      "534  69.4    0.0      -1.0      1.0      16.0       5.0  0.28125  0.388889   \n",
      "815  65.3    1.0      -1.0      1.0      13.0       5.0  0.34375  0.388889   \n",
      "710  66.2    1.0       1.0      1.0      12.0       5.0  0.56250  0.416667   \n",
      "..    ...    ...       ...      ...       ...       ...      ...       ...   \n",
      "503  81.8    0.0       1.0      3.0      17.0       5.0  0.59375  0.472222   \n",
      "380  68.1    1.0      -1.0      1.0      14.0       5.0  0.65625  0.527778   \n",
      "673  69.3    1.0       1.0      2.0      12.0       5.0  0.40625  0.416667   \n",
      "996  75.3    1.0       1.0      3.0      15.0       5.0  0.34375  0.250000   \n",
      "868  73.6    1.0      -1.0      1.0      18.0       5.0  0.81250  0.805556   \n",
      "\n",
      "     VISSPAT_AVG  PLAN_AVG  ...   MMSE_bl  ADAS11_bl  ADAS13_bl  \\\n",
      "886     0.250000    0.2500  ...  0.545455      0.250   0.365385   \n",
      "869     0.392857    0.5000  ...  0.636364      0.350   0.480769   \n",
      "534     0.250000    0.2500  ...  0.818182      0.400   0.461538   \n",
      "815     0.250000    0.2500  ...  0.909091      0.100   0.115385   \n",
      "710     0.285714    0.2500  ...  0.636364      0.125   0.153846   \n",
      "..           ...       ...  ...       ...        ...        ...   \n",
      "503     0.321429    0.3125  ...  1.000000      0.250   0.365385   \n",
      "380     0.357143    0.3125  ...  0.727273      0.250   0.307692   \n",
      "673     0.321429    0.3125  ...  0.909091      0.050   0.134615   \n",
      "996     0.350000    0.3750  ...  0.545455      0.500   0.576923   \n",
      "868     0.678571    0.6875  ...  0.818182      0.200   0.250000   \n",
      "\n",
      "     Ventricles_bl  Entorhinal_bl  RAVLT_immediate_bl  CEREBRUM_TCB  \\\n",
      "886       0.120647       0.479587            0.428571      0.694734   \n",
      "869       0.743950       0.747869            0.285714      0.675158   \n",
      "534       0.205525       0.325707            0.528571      0.362181   \n",
      "815       0.074043       0.692912            0.757143      0.461753   \n",
      "710       0.016264       0.531404            0.557143      0.223248   \n",
      "..             ...            ...                 ...           ...   \n",
      "503       0.232013       0.512786            0.542857      0.271870   \n",
      "380       0.397988       0.751907            0.471429      0.725783   \n",
      "673       0.108644       0.430686            0.628571      0.181497   \n",
      "996       0.210923       0.449978            0.242857      0.356262   \n",
      "868       0.227675       0.634365            0.385714      0.554300   \n",
      "\n",
      "     TOTAL_HIPPO  TOTAL_CSF  FAQTOTAL  \n",
      "886     0.586467   0.601852  0.033333  \n",
      "869     0.665300   0.788830  0.266667  \n",
      "534     0.508941   0.556446  0.166667  \n",
      "815     0.550115   0.197368  0.000000  \n",
      "710     0.454655   0.018945  0.000000  \n",
      "..           ...        ...       ...  \n",
      "503     0.486084   0.295056  0.000000  \n",
      "380     0.653656   0.461530  0.100000  \n",
      "673     0.437321   0.319292  0.066667  \n",
      "996     0.410425   0.425213  0.033333  \n",
      "868     0.445511   0.445385  0.400000  \n",
      "\n",
      "[155 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(cm)\n",
    "print(knn_predictions)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57.8, 0, 1, 1, 15, 7, 0.375, 0.277777777777778, 0.285714285714286, 0.25, 0.4, 0.375, 0.909090909090909, 0.075, 0.173076923076923, 0.100469439997525, 0.446612830865859, 0.6, 0.33799248307702, 0.488164816360999, 0.356406253240232, 0.066666666666667]] [1]\n"
     ]
    }
   ],
   "source": [
    "#model = knn(solver='DX_bl')\n",
    "#model.fit\n",
    "new_input = [[57.8,0,1,1,15,7,0.375,0.277777777777778,0.285714285714286,0.25,0.4,0.375,0.909090909090909,0.075,0.173076923076923,0.100469439997525,0.446612830865859,0.6,0.33799248307702,0.488164816360999,0.356406253240232,0.066666666666667]]\n",
    "output = knn.predict(new_input)\n",
    "print(new_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.17      0.25        42\n",
      "           1       0.75      0.95      0.84       113\n",
      "\n",
      "    accuracy                           0.74       155\n",
      "   macro avg       0.65      0.56      0.55       155\n",
      "weighted avg       0.70      0.74      0.68       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,knn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7870967741935484\n"
     ]
    }
   ],
   "source": [
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_train, y_train) \n",
    "gnb_predictions = gnb.predict(X_test) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test, y_test) \n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, gnb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72        42\n",
      "           1       1.00      0.71      0.83       113\n",
      "\n",
      "    accuracy                           0.79       155\n",
      "   macro avg       0.78      0.85      0.77       155\n",
      "weighted avg       0.88      0.79      0.80       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  0]\n",
      " [33 80]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-636585a00083>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.f1_score(X_test, y_test, labels=np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
